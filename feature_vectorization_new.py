import sys
import numpy as np
import pandas as pd
import json
import argparse
from db import connect_to_db
from db import get_database_name
from pymongo import errors


def main():
    parser = argparse.ArgumentParser()

    parser.add_argument("-i", "--inputSource", type=str, help="input source either csv or db", required=True)
    parser.add_argument("--outputCSV", default=False, action="store_true", help="output CSV",
                        required=False)
    parser.add_argument("--outputDB", default=False, action="store_true", help="output DB",
                        required=False)
    args = parser.parse_args()

    if args.inputSource == 'csv':
        input_df = pd.read_csv('csv_results/extractedFeatures.csv')
    elif args.inputSource == 'db':
        conn = connect_to_db()
        db = conn.get_database(get_database_name())
        input_df = pd.DataFrame(list(db.get_collection('extractedFeatures').find()))
    else:
        print("inputSource needs 'csv' or 'db' ")
        sys.exit()

    features = input_df['features']

    #type_names = ['permissions', 'activities', 'services', 'receivers', 'API_methods', 'API_classes']
    type_names = ['permissions', 'activities', 'services', 'receivers', 'intent-actions','intent-categories',
                  'API_methods', 'API_classes']

    all_types = divide_by_type(type_names, features)
    collections = {}
    for name in type_names:
        collections[name] = []

    # Compare each app's feature with total_feature. Features that are not common are treated as 0.
    for idx, app in input_df.iterrows():
        json_feauture = json.loads(app.features)
        for name in type_names:
            diff = list(set(all_types[name].columns.values.tolist()) - set(json_feauture[name]))
            all_types[name].loc[[idx], diff] = 0
            binary = all_types[name].loc[idx].to_list()
            data = {'binary': binary}
            collections[name].append(json.dumps(data))

    for name in type_names:
        # OUTPUT
        mat_name = name + 'BinaryVectors'
        output = pd.concat([input_df.loc[:, ('_id', 'app_name', 'label')],
                            pd.DataFrame(collections[name], columns=["binary_vectors"])], axis=1)
        if args.outputDB:
            print('db: ', mat_name)
            col = db.get_collection(mat_name)
            col.insert_many(json.loads(output.to_json(orient='records', default_handler=str)))

        if args.outputCSV:
            print('csv: ', mat_name)
            output.to_csv('csv_results/' + mat_name + '.csv', index=False)

    features_name = [json.dumps({'f': all_types[name].columns.to_list()}) for name in type_names]
    category_features = pd.DataFrame({'categories': type_names, 'features_name': features_name})
    mat_name = "categories_features"

    if args.outputDB:
        print('db: ', mat_name)
        col = db.get_collection(mat_name)
        col.insert_many(json.loads(category_features.to_json(orient='records', default_handler=str)))

    if args.outputCSV:
        print('csv: ', mat_name)
        category_features.to_csv('csv_results/' + mat_name + '.csv', index=False)


def divide_by_type(names, features):
    """ divide json by categories and create a matrix for each category
    """
    dic = {}
    for i in range(0, len(names)):
        print("divide: ", names[i])
        all_list = list(map(lambda x: np.array(json.loads(x)[names[i]]), features))
        all_array = np.concatenate(np.array(all_list))
        all_unique = np.unique(all_array)
        dic[names[i]] = pd.DataFrame(np.ones((len(features), len(all_unique))), dtype=int, columns=list(all_unique))
    return dic


if __name__ == "__main__":
    main()
