import sys
import numpy as np
import pandas as pd
import json
import argparse
from db import connect_to_db
from db import get_database_name
from pymongo import errors


def main():
    parser = argparse.ArgumentParser()

    parser.add_argument("-i", "--inputSource", type=str, help="input source either csv or db", required=True)
    parser.add_argument("--outputCSV", default=False, action="store_true", help="output CSV",
                        required=False)
    parser.add_argument("--outputDB", default=False, action="store_true", help="output DB",
                        required=False)
    args = parser.parse_args()

    if args.inputSource == 'csv':
        input_df = pd.read_csv('csv_results/extractedFeatures.csv')
    elif args.inputSource == 'db':
        conn = connect_to_db()
        db = conn.get_database(get_database_name())
        input_df = pd.DataFrame(list(db.get_collection('extractedFeatures').find()))
    else:
        print("inputSource needs 'csv' or 'db' ")
        sys.exit()

    features = input_df['features']
    type_names = ['permissions', 'activities', 'services', 'receivers', 'API_methods', 'API_classes']

    all_types = divide_by_type(type_names, features)

    # Compare each app's feature with total_feature. Features that are not common are treated as 0.
    for idx, app in input_df.iterrows():
        json_feauture = json.loads(app.features)
        for name in type_names:
            diff = list(set(all_types[name].columns.values.tolist()) - set(json_feauture[name]))
            all_types[name].loc[[idx], diff] = 0

    for name in type_names:
        # OUTPUT
        mat_name = name + 'VectorMatrix'
        output = pd.concat([input_df.loc[:, ('_id', 'app_name', 'label')], all_types[name]], axis=1)
        if args.outputDB:
            print('db: ', mat_name)
            col = db.get_collection(mat_name)
            if len(output) <= 10:
                col.insert_many(json.loads(output.to_json(orient='records', default_handler=str)))
            else:
                for i in range(0, len(output), 10):
                    seq = output[i:i + 10]
                    col.insert_many(json.loads(seq.to_json(orient='records', default_handler=str)))

        if args.outputCSV:
            print('csv: ', mat_name)
            output.to_csv('csv_results/' + mat_name + '.csv', index=False)


def divide_by_type(names, features):
    """ divide json by categories and create a matrix for each category
    """
    dic = {}
    for i in range(0, len(names)):
        print("divide: ", names[i])
        all_list = list(map(lambda x: np.array(json.loads(x)[names[i]]), features))
        all_array = np.concatenate(np.array(all_list))
        all_unique = np.unique(all_array)
        dic[names[i]] = pd.DataFrame(np.ones((len(features), len(all_unique))), dtype=int, columns=list(all_unique))
    return dic


if __name__ == "__main__":
    main()
