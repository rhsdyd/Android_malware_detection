import argparse
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.svm import SVC
from sklearn import metrics
import tensorflow as tf
import xgboost as xgb


def svm_10_fold(data, label, kfold):
    svm = SVC(C=100, gamma=0.0001, kernel="rbf")

    all_accuracies = []
    all_precisions = []
    all_recalls = []
    all_f1 = []
    f_no = 1

    print('-----------------------------SVM--------------------------------')
    for train, test in kfold.split(data):
        print('------------------------------------------------------------------------')
        print(f'Training for fold {f_no} ...')
        svm.fit(data.loc[train], label[train])
        pred = svm.predict(data.loc[test])
        accuracy = metrics.accuracy_score(label[test], pred)
        print('Accuracy: ', accuracy)

        all_accuracies.append(accuracy)
        all_precisions.append(metrics.precision_score(label[test], pred, pos_label='benign'))
        all_recalls.append(metrics.recall_score(label[test], pred, pos_label='benign'))
        all_f1.append(metrics.f1_score(label[test], pred, pos_label='benign'))

        f_no = f_no + 1
        print('------------------------------------------------------------------------')

    return np.mean(all_accuracies), np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1)


def xgb_10_fold(data, label, kfold):
    xgb_model = xgb.XGBClassifier(booster='gbtree',
                                  colsample_bylevel=0.9,
                                  colsample_bytree=0.8,
                                  gamma=0,
                                  max_depth=8,
                                  min_child_weight=3,
                                  n_estimators=50,
                                  nthread=4,
                                  objective='binary:logistic',
                                  random_state=2,
                                  silent=True)

    all_accuracies = []
    all_precisions = []
    all_recalls = []
    all_f1 = []
    f_no = 1

    print('-----------------------------XGBoost--------------------------------')
    for train, test in kfold.split(data):
        print('------------------------------------------------------------------------')
        print(f'Training for fold {f_no} ...')
        xgb_model.fit(data.loc[train], label[train], eval_set=[(data.loc[test], label[test])],
                      early_stopping_rounds=50)
        pred = xgb_model.predict(data.loc[test])
        accuracy = metrics.accuracy_score(label[test], pred)
        print('Accuracy: ', accuracy)

        all_accuracies.append(accuracy)
        all_precisions.append(metrics.precision_score(label[test], pred, pos_label='benign'))
        all_recalls.append(metrics.recall_score(label[test], pred, pos_label='benign'))
        all_f1.append(metrics.f1_score(label[test], pred, pos_label='benign'))

        f_no = f_no + 1
        print('------------------------------------------------------------------------')

    return np.mean(all_accuracies), np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1)


def dnn_10_fold(data, label, kfold):
    label[label == 'malware'] = 0
    label[label == 'benign'] = 1

    data = np.array(data, dtype=np.float32)
    label = np.array(label, dtype=np.float32)

    all_accuracies = []
    all_precisions = []
    all_recalls = []
    all_f1 = []
    f_no = 1

    tf.model = tf.keras.Sequential()
    tf.model.add(tf.keras.layers.Dense(units=10, input_dim=data.shape[1]))
    tf.model.add(tf.keras.layers.Activation('relu'))
    tf.model.add(tf.keras.layers.Dropout((0.2)))

    tf.model.add(tf.keras.layers.Dense(units=10))
    tf.model.add(tf.keras.layers.Activation('relu'))
    tf.model.add(tf.keras.layers.Dropout((0.2)))

    tf.model.add(tf.keras.layers.Dense(units=7))
    tf.model.add(tf.keras.layers.Activation('relu'))
    tf.model.add(tf.keras.layers.Dropout((0.2)))

    tf.model.add(tf.keras.layers.Dense(units=1))
    tf.model.add(tf.keras.layers.Activation('sigmoid'))
    tf.model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.1), metrics=['accuracy'])
    tf.model.summary()

    for train, test in kfold.split(data):
        print('------------------------------------------------------------------------')
        print(f'Training for fold {f_no} ...')
        # add callback param to fit()
        history = tf.model.fit(data[train], label[train], epochs=50)

        predictions = tf.model.predict(data[test])

        score = tf.model.evaluate(data[test], label[test])
        print('Accuracy: ', score[1])
        all_accuracies.append(score[1])

        pred = np.concatenate(predictions)
        pred[pred >= 0.5] = 1
        pred[pred < 0.5] = 0
        all_precisions.append(precision_score(label[test], pred))
        all_recalls.append(recall_score(label[test], pred))
        all_f1.append(f1_score(label[test], pred))

        f_no = f_no + 1
        print('------------------------------------------------------------------------')

    return np.mean(all_accuracies), np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1)
