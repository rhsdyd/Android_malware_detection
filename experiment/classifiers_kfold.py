import argparse
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.svm import SVC
from sklearn import metrics
import tensorflow as tf
import xgboost as xgb
import copy
import time

def svm_10_fold(data, label, kfold):
    svm = SVC(C=100, gamma=0.0001, kernel="rbf")

    all_accuracies = []
    all_precisions = []
    all_recalls = []
    all_f1 = []
    all_time = []
    f_no = 1

    print('-----------------------------SVM--------------------------------')
    for train, test in kfold.split(data):
        print('------------------------------------------------------------------------')
        print(f'Training for fold {f_no} ...')
        start_time = time.time()
        svm.fit(data.loc[train], label[train])
        end_time = time.time()
        pred = svm.predict(data.loc[test])
        accuracy = metrics.accuracy_score(label[test], pred)
        print('Accuracy: ', accuracy)

        all_time.append(end_time - start_time)
        all_accuracies.append(accuracy)
        all_precisions.append(metrics.precision_score(label[test], pred, pos_label='malware'))
        all_recalls.append(metrics.recall_score(label[test], pred, pos_label='malware'))
        all_f1.append(metrics.f1_score(label[test], pred, pos_label='malware'))

        f_no = f_no + 1
        print('------------------------------------------------------------------------')

    return np.mean(all_accuracies), np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1), np.mean(all_time)


def xgb_10_fold(data, label, kfold):
    xgb_model = xgb.XGBClassifier(booster='gbtree',
                                  colsample_bylevel=0.9,
                                  colsample_bytree=0.8,
                                  eta=0.3,
                                  gamma=0,
                                  max_depth=8,
                                  min_child_weight=3,
                                  n_estimators=50,
                                  nthread=4,
                                  objective='binary:logistic',
                                  random_state=2,
                                  silent=True)

    all_accuracies = []
    all_precisions = []
    all_recalls = []
    all_f1 = []
    all_time = []
    f_no = 1

    print('-----------------------------XGBoost--------------------------------')
    for train, test in kfold.split(data):
        print('------------------------------------------------------------------------')
        print(f'Training for fold {f_no} ...')
        start_time = time.time()
        xgb_model.fit(data.loc[train], label[train], eval_set=[(data.loc[test], label[test])],
                      early_stopping_rounds=50)
        end_time = time.time()
        pred = xgb_model.predict(data.loc[test])
        accuracy = metrics.accuracy_score(label[test], pred)
        print('Accuracy: ', accuracy)

        all_time.append(end_time - start_time)
        all_accuracies.append(accuracy)
        all_precisions.append(metrics.precision_score(label[test], pred, pos_label='malware'))
        all_recalls.append(metrics.recall_score(label[test], pred, pos_label='malware'))
        all_f1.append(metrics.f1_score(label[test], pred, pos_label='malware'))

        f_no = f_no + 1
        print('------------------------------------------------------------------------')

    return np.mean(all_accuracies), np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1), np.mean(all_time)


def dnn_10_fold(data, label, kfold):
    dnn_label = copy.deepcopy(label)
    dnn_data = copy.deepcopy(data)
    dnn_label[dnn_label == 'malware'] = 1
    dnn_label[dnn_label == 'benign'] = 0

    dnn_data = np.array(dnn_data, dtype=np.float32)
    dnn_label = np.array(dnn_label, dtype=np.float32)

    all_accuracies = []
    all_precisions = []
    all_recalls = []
    all_f1 = []
    all_time = []
    f_no = 1

    tf.model = tf.keras.Sequential()
    tf.model.add(tf.keras.layers.Dense(units=128, input_dim=dnn_data.shape[1]))
    tf.model.add(tf.keras.layers.Activation('relu'))
    tf.model.add(tf.keras.layers.Dropout((0.2)))

    tf.model.add(tf.keras.layers.Dense(units=64))
    tf.model.add(tf.keras.layers.Activation('relu'))
    tf.model.add(tf.keras.layers.Dropout((0.2)))

    tf.model.add(tf.keras.layers.Dense(units=32))
    tf.model.add(tf.keras.layers.Activation('relu'))
    tf.model.add(tf.keras.layers.Dropout((0.2)))

    tf.model.add(tf.keras.layers.Dense(units=1))
    tf.model.add(tf.keras.layers.Activation('sigmoid'))
    tf.model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=0.1), metrics=['accuracy'])
    tf.model.summary()

    for train, test in kfold.split(dnn_data):
        print('------------------------------------------------------------------------')
        print(f'Training for fold {f_no} ...')
        # add callback param to fit()
        start_time = time.time()
        history = tf.model.fit(dnn_data[train], dnn_label[train], epochs=100, batch_size=100)
        end_time = time.time()
        predictions = tf.model.predict(dnn_data[test])

        score = tf.model.evaluate(dnn_data[test], dnn_label[test])
        print('Accuracy: ', score[1])
        all_accuracies.append(score[1])

        pred = np.concatenate(predictions)
        pred[pred >= 0.5] = 1
        pred[pred < 0.5] = 0
        all_precisions.append(precision_score(dnn_label[test], pred))
        all_recalls.append(recall_score(dnn_label[test], pred))
        all_f1.append(f1_score(dnn_label[test], pred))
        all_time.append(end_time - start_time)
        f_no = f_no + 1
        print('------------------------------------------------------------------------')

    return np.mean(all_accuracies), np.mean(all_precisions), np.mean(all_recalls), np.mean(all_f1), np.mean(all_time)
