import sys
import numpy as np
import pandas as pd
import json
import argparse
from db import connect_to_db
from db import get_database_name
from feature_selection import helper
from pymongo import errors


def main():
    parser = argparse.ArgumentParser()

    parser.add_argument("--outputCSV", default=False, action="store_true", help="output CSV",
                        required=False)
    parser.add_argument("--outputDB", default=False, action="store_true", help="output DB",
                        required=False)
    args = parser.parse_args()

    conn = connect_to_db()
    db = conn.get_database(get_database_name())
    id_df = pd.DataFrame(list(db.get_collection('extractedFeatures').find()))
    categories_features = pd.DataFrame(list(db.get_collection('categories_features').find()))

    type_names = ['permissions', 'activities', 'services', 'receivers', 'API_methods', 'API_classes']

    ## cut out features with variance <= 0.0099( feature consists of 99% same values either 1 or 0)
    collections = {}
    for name in type_names:
        mat_name = name + 'BinaryVectors'
        vector_df = helper.chunk_read(mat_name, db)
        vector_df = vector_df.reset_index(drop=True)
        codes = vector_df['binary_vectors']
        all_list = list(map(lambda x: np.array(json.loads(x)['binary']), codes))
        features_json = json.loads(
            categories_features[categories_features.categories == name]['features_name'].values[0])
        vector_fs = pd.DataFrame(all_list, columns=features_json['f'])
        standard = vector_fs.var() > 0.0099
        selected_features = vector_fs.columns[standard]
        preprocessed_data = vector_fs[selected_features]
        collections[name] = preprocessed_data

    ## change each row to json format
    binary_code_collection = {}
    for name in type_names:
        binary_code_collection[name] = []
        for idx, app in collections[name].iterrows():
            binary = collections[name].loc[idx].to_list()
            data = {'binary': binary}
            binary_code_collection[name].append(json.dumps(data))

    for name in type_names:
        # OUTPUT
        mat_name = 'preprocessed_' + name + 'BinaryVectors'
        output = pd.concat([id_df.loc[:, ('_id', 'app_name', 'label')],
                            pd.DataFrame(binary_code_collection[name], columns=["binary_vectors"])], axis=1)
        if args.outputDB:
            print('db: ', mat_name)
            col = db.get_collection(mat_name)
            col.insert_many(json.loads(output.to_json(orient='records', default_handler=str)))

        if args.outputCSV:
            print('csv: ', mat_name)
            output.to_csv('csv_results/' + mat_name + '.csv', index=False)

    features_name = [json.dumps({'f': collections[name].columns.to_list()}) for name in type_names]
    category_features = pd.DataFrame({'categories': type_names, 'features_name': features_name})
    mat_name = "preprocessed_categories_features"

    if args.outputDB:
        print('db: ', mat_name)
        col = db.get_collection(mat_name)
        col.insert_many(json.loads(category_features.to_json(orient='records', default_handler=str)))

    if args.outputCSV:
        print('csv: ', mat_name)
        category_features.to_csv('csv_results/' + mat_name + '.csv', index=False)


if __name__ == "__main__":
    main()
