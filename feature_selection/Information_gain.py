import sys
import pandas as pd
import numpy as np
import json
import argparse
from db import connect_to_db
from db import get_database_name
from sklearn.feature_selection import chi2
from functools import reduce
from multiprocessing import Pool
from algorithm import IG
import helper

def main():
    parser = argparse.ArgumentParser()

    parser.add_argument("--outputCSV", default=False, action="store_true", help="output CSV",
                        required=False)
    parser.add_argument("--outputDB", default=False, action="store_true", help="output DB",
                        required=False)
    args = parser.parse_args()

    conn = connect_to_db()
    db = conn.get_database(get_database_name())
    permissions_df = helper.chunk_read('permissions', db)
    permissions_fs = permissions_df.drop(['_id', 'app_name', 'label'], axis='columns')
    permissions_fs.columns = 'p:' + permissions_fs.columns
    permissions_fs = pd.concat([permissions_df['_id'], permissions_fs], axis='columns')
    receivers_df = helper.chunk_read('receivers', db)
    receivers_fs = receivers_df.drop(['_id', 'app_name', 'label'], axis='columns')
    receivers_fs.columns = 'r:' + receivers_fs.columns
    receivers_fs = pd.concat([receivers_df['_id'], receivers_fs], axis='columns')
    services_df = helper.chunk_read('services', db)
    services_fs = services_df.drop(['_id', 'app_name', 'label'], axis='columns')
    services_fs.columns = 's:' + services_fs.columns
    services_fs = pd.concat([services_df['_id'], services_fs], axis='columns')

    dfs = [permissions_df[['_id', 'label']], permissions_fs, receivers_fs, services_fs]
    total_fs = reduce(lambda left, right: pd.merge(left, right, on='_id'), dfs)
    total_fs = total_fs.drop(['_id'], axis='columns')

    # multiprocessing :4 cores
    num_cores = 4
    pool = Pool(num_cores)
    job = helper.df_split(total_fs.drop(['label'], axis='columns'), total_fs['label'], 4)
    outputs = pool.map(IG.InfoGain, job)
    pool.close()
    pool.join()

    total_output = pd.concat([outputs[0], outputs[1], outputs[2], outputs[3]])
    mat_name = 'IG'

    if args.outputDB:
        print('db: ', mat_name)
        col = db.get_collection(mat_name)
        if len(total_output) <= 10:
            col.insert_many(json.loads(total_output.to_json(orient='records', default_handler=str)))
        else:
            for i in range(0, len(total_output), 10):
                seq = total_output[i:i + 10]
                col.insert_many(json.loads(seq.to_json(orient='records', default_handler=str)))

    if args.outputCSV:
        print('csv: ', mat_name)
        total_output.to_csv('csv_results/' + mat_name + '.csv', index=False)







if __name__ == "__main__":
    main()