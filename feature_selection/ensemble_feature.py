import pandas as pd
import numpy as np
import json
import argparse
from multiprocessing import Pool
from algorithm import IG
import helper
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))
from db import connect_to_db
from db import get_database_name


def main():
    parser = argparse.ArgumentParser()

    parser.add_argument("--outputCSV", default=False, action="store_true", help="output CSV",
                        required=False)
    parser.add_argument("--outputDB", default=False, action="store_true", help="output DB",
                        required=False)
    args = parser.parse_args()

    conn = connect_to_db()
    db = conn.get_database(get_database_name())

    chi = helper.chunk_read('chi_square_preprocessed_new', db)
    chi = chi.sort_values(by='CHI2', ascending=False, ignore_index=True)

    chi['chi_rank'] = np.arange(1,len(chi)+1)

    ig = helper.chunk_read('IG_preprocessed_new', db)
    ig = ig.sort_values(by='IG', ascending=False, ignore_index=True)

    ig['ig_rank'] = np.arange(1, len(ig)+1)

    ensemble = chi.sort_values(by='features', ascending=False, ignore_index=True)[['features', 'chi_rank']]
    ensemble['ig_rank'] = ig.sort_values(by='features', ascending=False, ignore_index=True)['ig_rank']

    ensemble['mean_rank'] = (ensemble['ig_rank'] + ensemble['chi_rank']) / 2

    mat_name = 'ensemble_feature'

    if args.outputDB:
        print('db: ', mat_name)
        col = db.get_collection(mat_name)
        if len(ensemble) <= 10:
            col.insert_many(json.loads(ensemble.to_json(orient='records', default_handler=str)))
        else:
            for i in range(0, len(ensemble), 10):
                seq = ensemble[i:i + 10]
                col.insert_many(json.loads(seq.to_json(orient='records', default_handler=str)))

    if args.outputCSV:
        print('csv: ', mat_name)
        ensemble.to_csv('csv_results/' + mat_name + '.csv', index=False)


if __name__ == "__main__":
    main()
